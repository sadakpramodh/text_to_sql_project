{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-llms-ollama\n",
      "  Downloading llama_index_llms_ollama-0.3.2-py3-none-any.whl.metadata (668 bytes)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from llama-index-llms-ollama) (0.11.10)\n",
      "Collecting ollama>=0.3.0 (from llama-index-llms-ollama)\n",
      "  Downloading ollama-0.3.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2.0.20)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2024.9.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (3.3)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (0.8.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.11.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (4.4.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.26.20)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (3.22.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (24.1)\n",
      "Downloading llama_index_llms_ollama-0.3.2-py3-none-any.whl (4.5 kB)\n",
      "Downloading ollama-0.3.3-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: ollama, llama-index-llms-ollama\n",
      "Successfully installed llama-index-llms-ollama-0.3.2 ollama-0.3.3\n"
     ]
    }
   ],
   "source": [
    "# Install ollama library from llama index\n",
    "# Follow instructions from https://github.com/ollama/ollama?tab=readme-ov-file\n",
    "\n",
    "\n",
    "! pip install llama-index-llms-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to download the model default 8B\n",
    "\n",
    "\n",
    "! ollama run llama3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham is a British-American programmer, entrepreneur, and writer. He's known for his insightful writings on technology, startups, and the culture of innovation.\n",
      "\n",
      "Here are some key aspects of his life and work:\n",
      "\n",
      "**Early life and education**: Graham was born in 1964 in Cambridge, England. He studied philosophy at Trinity College, Cambridge, but didn't graduate (he dropped out to pursue a career in software development).\n",
      "\n",
      "**Programming career**: In the late 1980s, Graham co-founded Viaweb, an online store for making custom t-shirts. Later sold to Yahoo! in 1998 for $49 million, this was his first success as a startup entrepreneur.\n",
      "\n",
      "**YC and Y Combinator**: In 2005, Graham helped found Y Combinator (YC), a seed-stage venture capital firm that provides funding and guidance to early-stage startups. As one of the co-founders, he played a key role in shaping YC's philosophy and approach to startup investing. Many successful companies have emerged from YC's incubation program, including Airbnb, Dropbox, and Reddit.\n",
      "\n",
      "**Writing**: Graham is also an accomplished writer, with articles published on his blog (also called \"Paul Graham\") and elsewhere. His writings cover topics like:\n",
      "\n",
      "1. The importance of innovation and entrepreneurship.\n",
      "2. How to create a startup ecosystem that fosters growth and learning.\n",
      "3. Insights into the human side of programming and technology.\n",
      "4. Observations on the nature of creativity, success, and failure.\n",
      "\n",
      "Some popular essays by Graham include \"How To Make Wealth Fall From the Sky\" (on creating value), \"The Superforecasters\" (on prediction and decision-making), and \"What You'll Wish You'd Known\" (a letter to a younger version of himself).\n",
      "\n",
      "**Other endeavors**: Graham has also been involved in various other ventures, including:\n",
      "\n",
      "1. The altMBA (Accelerated Master's Business Academy) online course program.\n",
      "2. Founding or investing in several startups through his company, YC.\n",
      "\n",
      "Overall, Paul Graham is a respected voice in the tech and startup communities, known for his insightful writings and contributions to entrepreneurship and innovation.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "llm = Ollama(model=\"llama3.1:latest\", request_timeout=120.0)\n",
    "resp = llm.complete(\"Who is Paul Graham?\")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To retrieve the top 5 rows from a table named \"alpha\", you can use the `LIMIT` clause in SQL. However, the exact syntax may vary slightly depending on whether you're using MySQL or another database management system like PostgreSQL or SQLite.\n",
      "\n",
      "### For MySQL:\n",
      "\n",
      "```sql\n",
      "SELECT *\n",
      "FROM alpha\n",
      "LIMIT 5;\n",
      "```\n",
      "\n",
      "This query selects all columns (`*`) from the table named \"alpha\" and limits the result to only the top 5 rows.\n",
      "\n",
      "### For PostgreSQL and SQLite:\n",
      "\n",
      "The same approach works for these databases as well, but it's worth noting that while `LIMIT` is supported in both, the context may differ slightly.\n",
      "\n",
      "```sql\n",
      "SELECT *\n",
      "FROM alpha\n",
      "ORDER BY rowid DESC -- or your preferred ordering method\n",
      "LIMIT 5;\n",
      "```\n",
      "\n",
      "However, if you simply need to get the first 5 rows (not necessarily ordered), you might want a slight adjustment:\n",
      "\n",
      "### For PostgreSQL and SQLite:\n",
      "\n",
      "```sql\n",
      "SELECT *\n",
      "FROM (\n",
      "  SELECT *\n",
      "  FROM alpha\n",
      ") AS subquery\n",
      "ORDER BY rowid DESC -- or your preferred ordering method\n",
      "LIMIT 5;\n",
      "```\n",
      "\n",
      "But, in most cases, especially if you're only dealing with `rowid`, this is overkill for simple retrieval tasks. If you just need the first rows without specific ordering considerations, using a direct approach like above should suffice.\n",
      "\n",
      "### For SQLite (when rowid isn't necessary):\n",
      "\n",
      "```sql\n",
      "SELECT *\n",
      "FROM (\n",
      "  SELECT *, ROW_NUMBER() OVER () AS rn\n",
      "  FROM alpha\n",
      ") AS subquery\n",
      "WHERE rn <= 5;\n",
      "```\n",
      "\n",
      "This query uses a window function (`ROW_NUMBER`) to assign an ID in ascending order, which allows you to select the first `n` rows easily.\n",
      "\n",
      "### Conclusion:\n",
      "\n",
      "The simplest and most efficient approach for most databases (like MySQL) is directly using `LIMIT`, while PostgreSQL and SQLite might require ordering by rowid or using window functions depending on your exact needs. Always consider your database system and specific requirements when crafting SQL queries.\n"
     ]
    }
   ],
   "source": [
    "resp = llm.complete(\"Write sql query to retrieve top 5 rows from alpha table\")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"Paul Graham\",\n",
      "\"profession\": [\"Programmer\", \"Entrepreneur\", \"Venture Capitalist\", \"Writer\"],\n",
      "\"biography\": \"Born on November 4, 1964, in Cambridge, England.\",\n",
      "\"education\": \"Ph.D. in Computer Science from Harvard University (1995)\",\n",
      "\"notable_works\": [\n",
      "\t{\"title\": \"Hacker News\",\n",
      "\t\"description\": \"A social news and discussion website he co-founded with Alexis Ohanian and Kiffin Transferred ownership to YCombinator in 2007\"},\n",
      "\t{\"title\": \"Y Combinator\",\n",
      "\t\"description\": \"A startup accelerator that provides seed funding to early-stage companies\"}\n",
      "],\n",
      "\"awards_and_recognition\":\n",
      "[\n",
      "\t{\"title\": \"Marvin Minsky Medal (2011)\",\n",
      "\t\"description\": \"Received for contributions to the field of Artificial Intelligence\"}\n",
      "]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"llama3.1:latest\", request_timeout=120.0, json_mode=True)\n",
    "response = llm.complete(\n",
    "    \"Who is Paul Graham? Output as a structured JSON object.\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"Paul Graham\", \" occupation\": \"Programmer, Entrepreneur, and Essayist\", \" birth_date\": \"1964\", \" education\": \"University of California, Berkeley (B.A.) and MIT (M.S.)\", \" notable_works\": [\"Hacking at CERN\", \"How to Make Wealth\", \"The Web Is a Computer for Humans\"], \" companies_founded\": [\"Viaweb\", \"Odeo\", \"Y Combinator\"], \" awards\": [\"Pauling Lecture Award\", \"MIT Technology Review's 50 Most Influential People in Technology\"]}\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"llama3.1:latest\", request_timeout=120.0, json_mode=True)\n",
    "response = llm.complete(\n",
    "    \"Who is Paul Graham? Output as a structured JSON object.\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## phoenix setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arize-phoenix\n",
      "  Downloading arize_phoenix-4.36.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting aioitertools (from arize-phoenix)\n",
      "  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting aiosqlite (from arize-phoenix)\n",
      "  Downloading aiosqlite-0.20.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting alembic<2,>=1.3.0 (from arize-phoenix)\n",
      "  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting arize-phoenix-evals>=0.13.1 (from arize-phoenix)\n",
      "  Downloading arize_phoenix_evals-0.16.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting arize-phoenix-otel>=0.4.1 (from arize-phoenix)\n",
      "  Downloading arize_phoenix_otel-0.5.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: cachetools in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from arize-phoenix) (5.5.0)\n",
      "Requirement already satisfied: fastapi in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from arize-phoenix) (0.114.2)\n",
      "Requirement already satisfied: grpcio in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from arize-phoenix) (1.66.1)\n",
      "Collecting hdbscan>=0.8.33 (from arize-phoenix)\n",
      "  Downloading hdbscan-0.8.38.post1.tar.gz (5.8 MB)\n",
      "     ---------------------------------------- 0.0/5.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/5.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/5.8 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.3/5.8 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 0.5/5.8 MB 1.3 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 1.0/5.8 MB 1.8 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 1.8/5.8 MB 2.5 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 3.1/5.8 MB 3.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 5.2/5.8 MB 4.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 5.8/5.8 MB 5.0 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: httpx in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from arize-phoenix) (0.27.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from arize-phoenix) (3.1.4)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from arize-phoenix) (1.26.4)\n",
      "Collecting openinference-instrumentation-langchain>=0.1.26 (from arize-phoenix)\n",
      "  Downloading openinference_instrumentation_langchain-0.1.28-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting openinference-instrumentation-llama-index>=2.2.1 (from arize-phoenix)\n",
      "  Downloading openinference_instrumentation_llama_index-3.0.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting openinference-instrumentation-openai>=0.1.11 (from arize-phoenix)\n",
      "  Downloading openinference_instrumentation_openai-0.1.14-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting openinference-instrumentation>=0.1.12 (from arize-phoenix)\n",
      "  Downloading openinference_instrumentation-0.1.18-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting openinference-semantic-conventions>=0.1.9 (from arize-phoenix)\n",
      "  Downloading openinference_semantic_conventions-0.1.10-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting opentelemetry-exporter-otlp (from arize-phoenix)\n",
      "  Downloading opentelemetry_exporter_otlp-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: opentelemetry-proto>=1.12.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from arize-phoenix) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-sdk in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from arize-phoenix) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from arize-phoenix) (0.48b0)\n",
      "Requirement already satisfied: pandas>=1.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from arize-phoenix) (2.2.2)\n",
      "Requirement already satisfied: protobuf<6.0,>=3.20 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from arize-phoenix) (4.25.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from arize-phoenix) (6.0.0)\n",
      "Collecting pyarrow (from arize-phoenix)\n",
      "  Using cached pyarrow-17.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: pydantic!=2.0.*,<3,>=1.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from arize-phoenix) (2.9.2)\n",
      "Collecting pyjwt (from arize-phoenix)\n",
      "  Downloading PyJWT-2.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting python-multipart (from arize-phoenix)\n",
      "  Downloading python_multipart-0.0.10-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from arize-phoenix) (1.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from arize-phoenix) (1.14.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=2.0.4 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from sqlalchemy[asyncio]<3,>=2.0.4->arize-phoenix) (2.0.20)\n",
      "Collecting sqlean-py>=3.45.1 (from arize-phoenix)\n",
      "  Downloading sqlean.py-3.45.1-cp312-cp312-win_amd64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: starlette in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from arize-phoenix) (0.38.5)\n",
      "Collecting strawberry-graphql==0.236.0 (from arize-phoenix)\n",
      "  Downloading strawberry_graphql-0.236.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from arize-phoenix) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from arize-phoenix) (4.12.2)\n",
      "Collecting umap-learn (from arize-phoenix)\n",
      "  Downloading umap_learn-0.5.6-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: uvicorn in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from arize-phoenix) (0.30.6)\n",
      "Requirement already satisfied: wrapt in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from arize-phoenix) (1.16.0)\n",
      "Collecting graphql-core<3.3.0,>=3.2.0 (from strawberry-graphql==0.236.0->arize-phoenix)\n",
      "  Downloading graphql_core-3.2.4-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from strawberry-graphql==0.236.0->arize-phoenix) (2.9.0.post0)\n",
      "Collecting Mako (from alembic<2,>=1.3.0->arize-phoenix)\n",
      "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from hdbscan>=0.8.33->arize-phoenix) (1.4.2)\n",
      "Requirement already satisfied: opentelemetry-api in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from openinference-instrumentation>=0.1.12->arize-phoenix) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from openinference-instrumentation-langchain>=0.1.26->arize-phoenix) (0.48b0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from pandas>=1.0->arize-phoenix) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from pandas>=1.0->arize-phoenix) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from pydantic!=2.0.*,<3,>=1.0->arize-phoenix) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from pydantic!=2.0.*,<3,>=1.0->arize-phoenix) (2.23.4)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from scikit-learn->arize-phoenix) (3.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from sqlalchemy<3,>=2.0.4->sqlalchemy[asyncio]<3,>=2.0.4->arize-phoenix) (3.1.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from starlette->arize-phoenix) (4.4.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from httpx->arize-phoenix) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from httpx->arize-phoenix) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from httpx->arize-phoenix) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from httpx->arize-phoenix) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from httpcore==1.*->httpx->arize-phoenix) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from jinja2->arize-phoenix) (2.1.5)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.27.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from opentelemetry-exporter-otlp->arize-phoenix) (1.27.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http==1.27.0 (from opentelemetry-exporter-otlp->arize-phoenix)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.27.0->opentelemetry-exporter-otlp->arize-phoenix) (1.2.14)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.27.0->opentelemetry-exporter-otlp->arize-phoenix) (1.65.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.27.0->opentelemetry-exporter-otlp->arize-phoenix) (1.27.0)\n",
      "Requirement already satisfied: requests~=2.7 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-http==1.27.0->opentelemetry-exporter-otlp->arize-phoenix) (2.32.3)\n",
      "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from opentelemetry-api->openinference-instrumentation>=0.1.12->arize-phoenix) (8.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from tqdm->arize-phoenix) (0.4.6)\n",
      "Collecting numba>=0.51.2 (from umap-learn->arize-phoenix)\n",
      "  Downloading numba-0.60.0-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting pynndescent>=0.5 (from umap-learn->arize-phoenix)\n",
      "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from uvicorn->arize-phoenix) (8.1.7)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.51.2->umap-learn->arize-phoenix)\n",
      "  Downloading llvmlite-0.43.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from python-dateutil<3.0.0,>=2.7.0->strawberry-graphql==0.236.0->arize-phoenix) (1.16.0)\n",
      "Requirement already satisfied: setuptools>=16.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from opentelemetry-instrumentation->openinference-instrumentation-langchain>=0.1.26->arize-phoenix) (75.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api->openinference-instrumentation>=0.1.12->arize-phoenix) (3.20.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.27.0->opentelemetry-exporter-otlp->arize-phoenix) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.27.0->opentelemetry-exporter-otlp->arize-phoenix) (1.26.20)\n",
      "Downloading arize_phoenix-4.36.0-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 27.9 MB/s eta 0:00:00\n",
      "Downloading strawberry_graphql-0.236.0-py3-none-any.whl (304 kB)\n",
      "Downloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
      "Downloading arize_phoenix_evals-0.16.0-py3-none-any.whl (56 kB)\n",
      "Downloading arize_phoenix_otel-0.5.1-py3-none-any.whl (10 kB)\n",
      "Downloading openinference_instrumentation-0.1.18-py3-none-any.whl (14 kB)\n",
      "Downloading openinference_instrumentation_langchain-0.1.28-py3-none-any.whl (16 kB)\n",
      "Downloading openinference_instrumentation_llama_index-3.0.2-py3-none-any.whl (25 kB)\n",
      "Downloading openinference_instrumentation_openai-0.1.14-py3-none-any.whl (23 kB)\n",
      "Downloading openinference_semantic_conventions-0.1.10-py3-none-any.whl (8.9 kB)\n",
      "Downloading sqlean.py-3.45.1-cp312-cp312-win_amd64.whl (783 kB)\n",
      "   ---------------------------------------- 0.0/783.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 783.0/783.0 kB 16.8 MB/s eta 0:00:00\n",
      "Downloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
      "Downloading aiosqlite-0.20.0-py3-none-any.whl (15 kB)\n",
      "Downloading opentelemetry_exporter_otlp-1.27.0-py3-none-any.whl (7.0 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_http-1.27.0-py3-none-any.whl (17 kB)\n",
      "Using cached pyarrow-17.0.0-cp312-cp312-win_amd64.whl (25.1 MB)\n",
      "Downloading PyJWT-2.9.0-py3-none-any.whl (22 kB)\n",
      "Downloading python_multipart-0.0.10-py3-none-any.whl (22 kB)\n",
      "Downloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n",
      "Downloading graphql_core-3.2.4-py3-none-any.whl (203 kB)\n",
      "Downloading numba-0.60.0-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 52.0 MB/s eta 0:00:00\n",
      "Downloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
      "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
      "Downloading llvmlite-0.43.0-cp312-cp312-win_amd64.whl (28.1 MB)\n",
      "   ---------------------------------------- 0.0/28.1 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 5.2/28.1 MB 53.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 16.3/28.1 MB 46.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 27.0/28.1 MB 47.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.0/28.1 MB 42.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.0/28.1 MB 42.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 28.1/28.1 MB 23.1 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: hdbscan\n",
      "  Building wheel for hdbscan (pyproject.toml): started\n",
      "  Building wheel for hdbscan (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for hdbscan: filename=hdbscan-0.8.38.post1-cp312-cp312-win_amd64.whl size=721893 sha256=bc1753b679318c884634ed05ba8d7617b41b50d1f70eb7a4ec87c555664dfd39\n",
      "  Stored in directory: c:\\users\\0201132\\appdata\\local\\pip\\cache\\wheels\\51\\1c\\fb\\cfac6918bd6a1478ab55a3da03c501046b67b8161309c2f64a\n",
      "Successfully built hdbscan\n",
      "Installing collected packages: sqlean-py, python-multipart, pyjwt, pyarrow, openinference-semantic-conventions, Mako, llvmlite, graphql-core, aiosqlite, aioitertools, strawberry-graphql, numba, alembic, pynndescent, hdbscan, arize-phoenix-evals, umap-learn, opentelemetry-exporter-otlp-proto-http, openinference-instrumentation, opentelemetry-exporter-otlp, openinference-instrumentation-openai, openinference-instrumentation-llama-index, openinference-instrumentation-langchain, arize-phoenix-otel, arize-phoenix\n",
      "Successfully installed Mako-1.3.5 aioitertools-0.12.0 aiosqlite-0.20.0 alembic-1.13.2 arize-phoenix-4.36.0 arize-phoenix-evals-0.16.0 arize-phoenix-otel-0.5.1 graphql-core-3.2.4 hdbscan-0.8.38.post1 llvmlite-0.43.0 numba-0.60.0 openinference-instrumentation-0.1.18 openinference-instrumentation-langchain-0.1.28 openinference-instrumentation-llama-index-3.0.2 openinference-instrumentation-openai-0.1.14 openinference-semantic-conventions-0.1.10 opentelemetry-exporter-otlp-1.27.0 opentelemetry-exporter-otlp-proto-http-1.27.0 pyarrow-17.0.0 pyjwt-2.9.0 pynndescent-0.5.13 python-multipart-0.0.10 sqlean-py-3.45.1 strawberry-graphql-0.236.0 umap-learn-0.5.6\n"
     ]
    }
   ],
   "source": [
    "! pip install arize-phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gcsfs\n",
      "  Downloading gcsfs-2024.9.0.post1-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from gcsfs) (3.10.5)\n",
      "Requirement already satisfied: decorator>4.1.2 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from gcsfs) (5.1.1)\n",
      "Requirement already satisfied: fsspec==2024.9.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from gcsfs) (2024.9.0)\n",
      "Requirement already satisfied: google-auth>=1.2 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from gcsfs) (2.34.0)\n",
      "Collecting google-auth-oauthlib (from gcsfs)\n",
      "  Downloading google_auth_oauthlib-1.2.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-cloud-storage (from gcsfs)\n",
      "  Downloading google_cloud_storage-2.18.2-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from gcsfs) (2.32.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.11.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from google-auth>=1.2->gcsfs) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from google-auth>=1.2->gcsfs) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from google-auth>=1.2->gcsfs) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from google-auth-oauthlib->gcsfs) (2.0.0)\n",
      "Collecting google-api-core<3.0.0dev,>=2.15.0 (from google-cloud-storage->gcsfs)\n",
      "  Downloading google_api_core-2.20.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0 (from google-cloud-storage->gcsfs)\n",
      "  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media>=2.7.2 (from google-cloud-storage->gcsfs)\n",
      "  Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage->gcsfs)\n",
      "  Downloading google_crc32c-1.6.0-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from requests->gcsfs) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from requests->gcsfs) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from requests->gcsfs) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from requests->gcsfs) (2024.8.30)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (1.65.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs) (4.25.5)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs)\n",
      "  Using cached proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\0201132\\documents\\projects\\text_to_sql_project\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.2)\n",
      "Downloading gcsfs-2024.9.0.post1-py2.py3-none-any.whl (34 kB)\n",
      "Downloading google_auth_oauthlib-1.2.1-py2.py3-none-any.whl (24 kB)\n",
      "Downloading google_cloud_storage-2.18.2-py2.py3-none-any.whl (130 kB)\n",
      "Downloading google_api_core-2.20.0-py3-none-any.whl (142 kB)\n",
      "Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_crc32c-1.6.0-cp312-cp312-win_amd64.whl (33 kB)\n",
      "Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "Using cached proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "Installing collected packages: proto-plus, google-crc32c, google-resumable-media, google-auth-oauthlib, google-api-core, google-cloud-core, google-cloud-storage, gcsfs\n",
      "Successfully installed gcsfs-2024.9.0.post1 google-api-core-2.20.0 google-auth-oauthlib-1.2.1 google-cloud-core-2.4.1 google-cloud-storage-2.18.2 google-crc32c-1.6.0 google-resumable-media-2.7.2 proto-plus-1.24.0\n"
     ]
    }
   ],
   "source": [
    "! pip install gcsfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Existing running Phoenix instance detected! Shutting it down and starting a new instance...\n",
      "Attempting to instrument while already instrumented\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌍 To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "📖 For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n",
      "{\"name\": \"Paul Graham\",\n",
      " \" occupation\": \"Entrepreneur, Programmer, Venture Capitalist, and Writer\",\n",
      " \"birth_date\": \"August 6, 1964\",\n",
      " \"nationality\": \"American (UK-born)\",\n",
      " \"education\": \"University of California, Berkeley (B.S., M.S.)\",\n",
      " \"known_for\": [\n",
      "   \"Co-founder of Y Combinator\",\n",
      "   \"Founder of Viaweb, which was later sold to Yahoo!\",\n",
      "   \"Notable essays and articles on startup culture and technology\"\n",
      " ],\n",
      " \"awards\": [\n",
      "   \"Member of the National Academy of Engineering (2016)\"\n",
      " ],\n",
      " \"links\": {\n",
      "  \"twitter\": \"https://twitter.com/paulg\",\n",
      "  \"blog\": \"http://paulgraham.com/\"\n",
      " },\n",
      " \"biography\": \"Paul Graham is an American entrepreneur, programmer, venture capitalist, and writer. He co-founded Y Combinator in 2005 with Robert Tappan Morris and Jessica Livingston. Prior to that, he co-founded Viaweb, a web-based spreadsheet program, which was sold to Yahoo! for $125 million in 2000. Graham is also known for his essays on startup culture and technology, which are published on his blog.\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://localhost:6006/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import phoenix as px\n",
    "from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
    "import os\n",
    "from gcsfs import GCSFileSystem\n",
    "from llama_index.core import (\n",
    "    Settings,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    set_global_handler,\n",
    "    load_index_from_storage\n",
    ")\n",
    "# from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "# from llama_index.llms.openai import OpenAI\n",
    "import llama_index\n",
    "\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "\n",
    "\n",
    "\n",
    "# To view traces in Phoenix, you will first have to start a Phoenix server. You can do this by running the following:\n",
    "session = px.launch_app()\n",
    "\n",
    "# Initialize LlamaIndex auto-instrumentation\n",
    "LlamaIndexInstrumentor().instrument()\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"<ENTER_YOUR_OPENAI_API_KEY_HERE>\"\n",
    "\n",
    "# LlamaIndex application initialization may vary\n",
    "# depending on your application\n",
    "Settings.llm = Ollama(model=\"llama3.1:latest\", request_timeout=120.0, json_mode=True)\n",
    "Settings.embed_model = OllamaEmbedding(\n",
    "    model_name=\"llama3.1:latest\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    ollama_additional_kwargs={\"mirostat\": 0},\n",
    ")\n",
    "\n",
    "# Load your data and create an index. Here we've provided an example of our documentation\n",
    "file_system = GCSFileSystem(project=\"public-assets-275721\")\n",
    "index_path = \"arize-phoenix-assets/datasets/unstructured/llm/llama-index/arize-docs/index/\"\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    fs=file_system,\n",
    "    persist_dir=index_path,\n",
    ")\n",
    "\n",
    "index = load_index_from_storage(storage_context)\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# Query your LlamaIndex application\n",
    "query_engine.query(\"What is the meaning of life?\")\n",
    "query_engine.query(\"How can I deploy Arize?\")\n",
    "\n",
    "# View the traces in the Phoenix UI\n",
    "px.active_session().url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import phoenix as px\n",
    "\n",
    "train_df = pd.read_parquet(\n",
    "    \"http://storage.googleapis.com/arize-assets/phoenix/datasets/unstructured/cv/human-actions/human_actions_training.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_id</th>\n",
       "      <th>prediction_ts</th>\n",
       "      <th>url</th>\n",
       "      <th>image_vector</th>\n",
       "      <th>actual_action</th>\n",
       "      <th>predicted_action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>595d87df-5d50-4d60-bc5f-3ad1cc483190</td>\n",
       "      <td>1.655757e+09</td>\n",
       "      <td>https://storage.googleapis.com/arize-assets/fi...</td>\n",
       "      <td>[0.26720312, 0.02652928, 0.0, 0.028591828, 0.0...</td>\n",
       "      <td>drinking</td>\n",
       "      <td>drinking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37596b85-c007-4e4f-901d-b87e5297d4b8</td>\n",
       "      <td>1.655757e+09</td>\n",
       "      <td>https://storage.googleapis.com/arize-assets/fi...</td>\n",
       "      <td>[0.08745878, 0.0, 0.16057675, 0.036570743, 0.0...</td>\n",
       "      <td>fighting</td>\n",
       "      <td>fighting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b048d389-539a-4ffb-be61-2f4daa52e700</td>\n",
       "      <td>1.655757e+09</td>\n",
       "      <td>https://storage.googleapis.com/arize-assets/fi...</td>\n",
       "      <td>[0.9822482, 0.0, 0.037284207, 0.017358225, 0.2...</td>\n",
       "      <td>clapping</td>\n",
       "      <td>clapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3e00c023-49b4-49c2-9922-7ecbf1349c04</td>\n",
       "      <td>1.655757e+09</td>\n",
       "      <td>https://storage.googleapis.com/arize-assets/fi...</td>\n",
       "      <td>[0.028404092, 0.063946, 1.0448836, 0.65191674,...</td>\n",
       "      <td>fighting</td>\n",
       "      <td>fighting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fb38b050-fb12-43af-b27d-629653b5df86</td>\n",
       "      <td>1.655758e+09</td>\n",
       "      <td>https://storage.googleapis.com/arize-assets/fi...</td>\n",
       "      <td>[0.06121698, 0.5172761, 0.50730985, 0.5771937,...</td>\n",
       "      <td>sitting</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          prediction_id  prediction_ts  \\\n",
       "0  595d87df-5d50-4d60-bc5f-3ad1cc483190   1.655757e+09   \n",
       "1  37596b85-c007-4e4f-901d-b87e5297d4b8   1.655757e+09   \n",
       "2  b048d389-539a-4ffb-be61-2f4daa52e700   1.655757e+09   \n",
       "3  3e00c023-49b4-49c2-9922-7ecbf1349c04   1.655757e+09   \n",
       "4  fb38b050-fb12-43af-b27d-629653b5df86   1.655758e+09   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://storage.googleapis.com/arize-assets/fi...   \n",
       "1  https://storage.googleapis.com/arize-assets/fi...   \n",
       "2  https://storage.googleapis.com/arize-assets/fi...   \n",
       "3  https://storage.googleapis.com/arize-assets/fi...   \n",
       "4  https://storage.googleapis.com/arize-assets/fi...   \n",
       "\n",
       "                                        image_vector actual_action  \\\n",
       "0  [0.26720312, 0.02652928, 0.0, 0.028591828, 0.0...      drinking   \n",
       "1  [0.08745878, 0.0, 0.16057675, 0.036570743, 0.0...      fighting   \n",
       "2  [0.9822482, 0.0, 0.037284207, 0.017358225, 0.2...      clapping   \n",
       "3  [0.028404092, 0.063946, 1.0448836, 0.65191674,...      fighting   \n",
       "4  [0.06121698, 0.5172761, 0.50730985, 0.5771937,...       sitting   \n",
       "\n",
       "  predicted_action  \n",
       "0         drinking  \n",
       "1         fighting  \n",
       "2         clapping  \n",
       "3         fighting  \n",
       "4          sitting  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Schema to indicate which columns in train_df should map to each field\n",
    "train_schema = px.Schema(\n",
    "    timestamp_column_name=\"prediction_ts\",\n",
    "    prediction_label_column_name=\"predicted_action\",\n",
    "    actual_label_column_name=\"actual_action\",\n",
    "    embedding_feature_column_names={\n",
    "        \"image_embedding\": px.EmbeddingColumnNames(\n",
    "            vector_column_name=\"image_vector\",\n",
    "            link_to_data_column_name=\"url\",\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Existing running Phoenix instance detected! Shutting it down and starting a new instance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌍 To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "📖 For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\0201132\\Documents\\Projects\\text_to_sql_project\\venv\\Lib\\site-packages\\phoenix\\server\\api\\types\\EmbeddingDimension.py:425: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  prediction_id=dataset[PREDICTION_ID][row_id],\n",
      "c:\\Users\\0201132\\Documents\\Projects\\text_to_sql_project\\venv\\Lib\\site-packages\\phoenix\\server\\api\\types\\EmbeddingDimension.py:426: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  link_to_data=dataset[self.dimension.link_to_data][row_id],\n",
      "c:\\Users\\0201132\\Documents\\Projects\\text_to_sql_project\\venv\\Lib\\site-packages\\phoenix\\server\\api\\types\\EmbeddingDimension.py:427: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  raw_data=dataset[self.dimension.raw_data][row_id],\n",
      "c:\\Users\\0201132\\Documents\\Projects\\text_to_sql_project\\venv\\Lib\\site-packages\\phoenix\\server\\api\\types\\EmbeddingDimension.py:448: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  prediction_label=dataset[PREDICTION_LABEL][row_id],\n",
      "c:\\Users\\0201132\\Documents\\Projects\\text_to_sql_project\\venv\\Lib\\site-packages\\phoenix\\server\\api\\types\\EmbeddingDimension.py:449: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  prediction_score=dataset[PREDICTION_SCORE][row_id],\n",
      "c:\\Users\\0201132\\Documents\\Projects\\text_to_sql_project\\venv\\Lib\\site-packages\\phoenix\\server\\api\\types\\EmbeddingDimension.py:450: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  actual_label=dataset[ACTUAL_LABEL][row_id],\n",
      "c:\\Users\\0201132\\Documents\\Projects\\text_to_sql_project\\venv\\Lib\\site-packages\\phoenix\\server\\api\\types\\EmbeddingDimension.py:451: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  actual_score=dataset[ACTUAL_SCORE][row_id],\n",
      "c:\\Users\\0201132\\Documents\\Projects\\text_to_sql_project\\venv\\Lib\\site-packages\\phoenix\\server\\api\\types\\EmbeddingDimension.py:425: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  prediction_id=dataset[PREDICTION_ID][row_id],\n",
      "c:\\Users\\0201132\\Documents\\Projects\\text_to_sql_project\\venv\\Lib\\site-packages\\phoenix\\server\\api\\types\\EmbeddingDimension.py:426: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  link_to_data=dataset[self.dimension.link_to_data][row_id],\n",
      "c:\\Users\\0201132\\Documents\\Projects\\text_to_sql_project\\venv\\Lib\\site-packages\\phoenix\\server\\api\\types\\EmbeddingDimension.py:427: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  raw_data=dataset[self.dimension.raw_data][row_id],\n",
      "c:\\Users\\0201132\\Documents\\Projects\\text_to_sql_project\\venv\\Lib\\site-packages\\phoenix\\server\\api\\types\\EmbeddingDimension.py:448: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  prediction_label=dataset[PREDICTION_LABEL][row_id],\n",
      "c:\\Users\\0201132\\Documents\\Projects\\text_to_sql_project\\venv\\Lib\\site-packages\\phoenix\\server\\api\\types\\EmbeddingDimension.py:449: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  prediction_score=dataset[PREDICTION_SCORE][row_id],\n",
      "c:\\Users\\0201132\\Documents\\Projects\\text_to_sql_project\\venv\\Lib\\site-packages\\phoenix\\server\\api\\types\\EmbeddingDimension.py:450: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  actual_label=dataset[ACTUAL_LABEL][row_id],\n",
      "c:\\Users\\0201132\\Documents\\Projects\\text_to_sql_project\\venv\\Lib\\site-packages\\phoenix\\server\\api\\types\\EmbeddingDimension.py:451: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  actual_score=dataset[ACTUAL_SCORE][row_id],\n"
     ]
    }
   ],
   "source": [
    "train_ds = px.Inferences(dataframe=train_df, schema=train_schema, name=\"training\")\n",
    "session = px.launch_app(primary=train_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
